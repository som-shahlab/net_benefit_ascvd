{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zipcode_cvd.experiments.util import flatten_multicolumns\n",
    "import itertools\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_data_path = '../zipcode_cvd/experiments/figures_data/eo_rr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['race_eth', 'gender_concept_name', 'race_eth_gender']\n",
    "data_dict = {\n",
    "    attribute: pd.read_parquet(os.path.join(figures_data_path, f'result_df_ci_performance_{attribute}.parquet'))\n",
    "    for attribute in attributes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name_dict = {\n",
    "    'race_eth': pd.DataFrame(\n",
    "        {\n",
    "            'Asian': 'Asian',\n",
    "            'Black or African American': 'Black',\n",
    "            'Hispanic or Latino': 'Hispanic',\n",
    "            'Other': 'Other',\n",
    "            'White': 'White',\n",
    "            'overall': 'Overall'\n",
    "        }, index=['_race_eth']).transpose().rename_axis('race_eth').reset_index(),\n",
    "    'gender_concept_name': pd.DataFrame({\n",
    "        'FEMALE': 'Female',\n",
    "        'MALE': 'Male',\n",
    "        'overall': 'Overall'\n",
    "    }, index=['_gender_concept_name']).transpose().rename_axis('gender_concept_name').reset_index(),\n",
    "    'race_eth_gender': pd.DataFrame(\n",
    "        {\n",
    "        'Asian | FEMALE': 'A-F',\n",
    "        'Asian | MALE': 'A-M',\n",
    "        'Black or African American | MALE': 'B-M',\n",
    "        'Black or African American | FEMALE': 'B-F',\n",
    "        'Hispanic or Latino | MALE': 'H-M',\n",
    "        'Hispanic or Latino | FEMALE': 'H-F',\n",
    "        'Other | FEMALE': 'O-F',\n",
    "        'Other | MALE': 'O-M',\n",
    "        'White | FEMALE': 'W-F',\n",
    "        'White | MALE': 'W-M',\n",
    "        'overall': 'Overall'\n",
    "    }, index=['_race_eth_gender']).transpose().rename_axis('race_eth_gender').reset_index(),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    key: value.merge(group_name_dict[key]).drop(columns=key).rename(columns={f'_{key}': key})\n",
    "    for key, value in data_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['gender_concept_name'].gender_concept_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_pivot = {}\n",
    "for key, value in data_dict.items():\n",
    "    data_dict_pivot[key] = value.pivot(\n",
    "        index = set(value.columns) - set(['comparator', 'baseline', 'delta', 'CI_quantile_95', 'metric']),\n",
    "        columns=['metric', 'CI_quantile_95'],\n",
    "        values=['comparator', 'delta']\n",
    "    ).pipe(flatten_multicolumns).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(\n",
    "    df, \n",
    "    ax=None, \n",
    "    x_var='score',\n",
    "    y_var='calibration_density', \n",
    "    group_var_name='race_eth_gender', \n",
    "    ci_lower_var=None,\n",
    "    ci_upper_var=None,\n",
    "    ci_type='fill',\n",
    "    drawstyle=None, \n",
    "    ylim=(None, None),\n",
    "    xlim=(None, None),\n",
    "    ylabel=None,\n",
    "    xlabel=None,\n",
    "    legend=True,\n",
    "    bbox_to_anchor=(1.04, 1),\n",
    "    plot_y_equals_x=False,\n",
    "    plot_x_axis=False,\n",
    "    despine=True,\n",
    "    hide_yticks=False,\n",
    "    hide_xticks=False,\n",
    "    linestyle=None,\n",
    "    label_group=True,\n",
    "    title=None,\n",
    "    axvline=None,\n",
    "    y_labelpad=None,\n",
    "    ylabel_fontsize=None,\n",
    "    xticks=None,\n",
    "    xticklabels=None,\n",
    "    use_symlog_x=False,\n",
    "    symlog_x_linthresh=1e-2,\n",
    "    errorbar_capsize=0.0,\n",
    "    groupby_sort=True\n",
    "):\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "\n",
    "    groups = []\n",
    "    for i, (group_id, group_df) in enumerate(df.groupby(group_var_name, sort=groupby_sort)):\n",
    "        groups.append(group_id)\n",
    "        color = plt.rcParams['axes.prop_cycle'].by_key()['color'][i%len(plt.rcParams['axes.prop_cycle'])]\n",
    "        ax.plot(group_df[x_var], group_df[y_var], drawstyle=drawstyle, color=color, linestyle=linestyle, label=group_id if label_group else None)\n",
    "        if ci_upper_var is not None and ci_lower_var is not None:\n",
    "            if ci_type == \"fill\":\n",
    "                ax.fill_between(\n",
    "                    group_df[x_var], \n",
    "                    group_df[ci_lower_var], \n",
    "                    group_df[ci_upper_var],\n",
    "                    alpha=0.25,\n",
    "                    color=color,\n",
    "                    label='_nolegend_'\n",
    "                )\n",
    "            elif ci_type == 'errorbar':\n",
    "                ax.errorbar(\n",
    "                    x=group_df[x_var],\n",
    "                    y=group_df[y_var],\n",
    "                    yerr=[group_df[y_var] - group_df[ci_lower_var], group_df[ci_upper_var] - group_df[y_var]],\n",
    "                    capsize=errorbar_capsize,\n",
    "                    label=\"_nolegend_\"\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError('Invalid ci_type')\n",
    "    \n",
    "    if use_symlog_x:\n",
    "        ax.set_xscale('symlog', linthresh=symlog_x_linthresh)\n",
    "        \n",
    "    if plot_y_equals_x:\n",
    "        ax.plot(np.linspace(1e-4, 1-1e-4, 1000), np.linspace(1e-4, 1-1e-4, 1000), linestyle='--', color='k', label='_nolegend_')\n",
    "        \n",
    "    if axvline is not None:\n",
    "        ax.axvline(axvline, linestyle='--', color='k', label=\"_nolegend_\")\n",
    "    \n",
    "    if plot_x_axis:\n",
    "        ax.axhline(0, linestyle='--', color='k', label=\"_nolegend_\")\n",
    "        \n",
    "    if legend:\n",
    "        ax.legend(labels=groups, bbox_to_anchor=bbox_to_anchor, frameon=False)\n",
    "    \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    if xlabel is not None:\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "    if ylabel is not None:\n",
    "        ax.set_ylabel(ylabel, labelpad=y_labelpad, fontsize=ylabel_fontsize)\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    if hide_xticks:\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "    elif xticks is not None:\n",
    "        ax.set_xticks(xticks)\n",
    "        if xticklabels is not None:\n",
    "            ax.set_xticklabels(xticklabels)\n",
    "            \n",
    "    if hide_yticks:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "    \n",
    "    if despine:\n",
    "        sns.despine()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_label_dict = {\n",
    "    ('auc', 'comparator'): 'AUC',\n",
    "    ('loss_bce', 'comparator'): 'Loss',\n",
    "    ('ace_abs_logistic_logit', 'comparator'): 'ACE',\n",
    "    ('net_benefit_rr_0.075', 'comparator'): 'NB (7.5%)',\n",
    "    ('net_benefit_rr_0.2', 'comparator'): 'NB (20%)',\n",
    "    ('net_benefit_rr_recalib_0.075', 'comparator'): 'cNB (7.5%)',\n",
    "    ('net_benefit_rr_recalib_0.2', 'comparator'): 'cNB (20%)',\n",
    "    ('auc', 'delta'): 'AUC (rel)',\n",
    "    ('loss_bce', 'delta'): 'Loss (rel)',\n",
    "    ('ace_abs_logistic_logit', 'delta'): 'ACE (rel)',\n",
    "    ('net_benefit_rr_0.075', 'delta'): 'NB (7.5%, rel)',\n",
    "    ('net_benefit_rr_0.2', 'delta'): 'NB (20%, rel)',\n",
    "    ('net_benefit_rr_recalib_0.075', 'delta'): 'cNB (7.5%, rel)',\n",
    "    ('net_benefit_rr_recalib_0.2', 'delta'): 'cNB (20%, rel)',\n",
    "}\n",
    "ylabel_dict = {\n",
    "    'comparator': 'Absolute',\n",
    "    'delta': 'Relative'\n",
    "}\n",
    "plot_keys_metrics_dict = {\n",
    "    'performance': ['auc', 'loss_bce', 'ace_abs_logistic_logit'],\n",
    "    'net_benefit': ['net_benefit_rr_0.075', 'net_benefit_rr_recalib_0.075', 'net_benefit_rr_0.2', 'net_benefit_rr_recalib_0.2'],\n",
    "}\n",
    "\n",
    "plot_grid_config = {\n",
    "    'race_eth': {\n",
    "        'bbox_to_anchor': (1.05, 0.65),\n",
    "    },\n",
    "    'gender_concept_name': {\n",
    "        'bbox_to_anchor': (1.05, 0.65),\n",
    "    },\n",
    "    'race_eth_gender': {\n",
    "        'bbox_to_anchor': (1.02, 0.85),\n",
    "    }\n",
    "}\n",
    "plot_config = {\n",
    "    ('race_eth', 'comparator', 'net_benefit'): {\n",
    "        'ylim': (-0.0025, 0.025)\n",
    "    },\n",
    "    ('race_eth', 'delta', 'net_benefit'): {\n",
    "        'ylim': (-0.01, 0.0025)\n",
    "    },\n",
    "    ('gender_concept_name', 'comparator', 'net_benefit'): {\n",
    "        'ylim': (-0.0025, 0.025)\n",
    "    },\n",
    "    ('gender_concept_name', 'delta', 'net_benefit'): {\n",
    "        'ylim': (-0.01, 0.0025)\n",
    "    },\n",
    "    ('race_eth_gender', 'comparator', 'net_benefit'): {\n",
    "        'ylim': (-0.0025, 0.025)\n",
    "    },\n",
    "    ('race_eth_gender', 'delta', 'net_benefit'): {\n",
    "        'ylim': (-0.01, 0.0025)\n",
    "    },\n",
    "    ('race_eth', 'comparator', 'performance'): {\n",
    "    },\n",
    "    ('race_eth', 'delta', 'performance'): {\n",
    "    },\n",
    "    ('gender_concept_name', 'comparator', 'performance'): {\n",
    "    },\n",
    "    ('gender_concept_name', 'delta', 'performance'): {\n",
    "    },\n",
    "    ('race_eth_gender', 'comparator', 'performance'): {\n",
    "    },\n",
    "    ('race_eth_gender', 'delta', 'performance'): {\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_grid(\n",
    "    df, \n",
    "    group_var_name, \n",
    "    metrics, \n",
    "    plot_key,\n",
    "    metric_prefixes=['comparator', 'delta'],\n",
    "    wspace=0.2, \n",
    "    hspace=0.25,\n",
    "    bbox_to_anchor=(1.05, 0.65),\n",
    "    xlabel_height=-0.05,\n",
    "    sharey=None\n",
    "):\n",
    "    \n",
    "    fig, ax_list = plt.subplots(\n",
    "        len(metric_prefixes), len(metrics), squeeze=False, figsize=(10,1.5*len(metric_prefixes)), dpi=180,\n",
    "        sharey=sharey\n",
    "    )\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "    for j, metric in enumerate(metrics):\n",
    "        for i, metric_prefix in enumerate(metric_prefixes):\n",
    "            plot_data(\n",
    "                df.query(f'{group_var_name} != \"Overall\"'), \n",
    "                ax=ax_list[i, j],\n",
    "                x_var='lambda_group_regularization', \n",
    "                y_var=f'{metric_prefix}_{metric}_mid', \n",
    "                group_var_name=group_var_name,\n",
    "                use_symlog_x=True,\n",
    "                symlog_x_linthresh=1e-2,\n",
    "                ci_lower_var=f'{metric_prefix}_{metric}_lower',\n",
    "                ci_upper_var=f'{metric_prefix}_{metric}_upper',\n",
    "                ci_type='errorbar',\n",
    "                errorbar_capsize=3,\n",
    "                plot_x_axis=metric_prefix == \"delta\",\n",
    "                legend=False,\n",
    "                hide_xticks=i + 1 < len(metric_prefixes),\n",
    "                title=metric_label_dict[(metric, metric_prefix)] if i == 0 else None,\n",
    "                ylabel=ylabel_dict[metric_prefix] if j == 0 else None,\n",
    "                ylabel_fontsize=12,\n",
    "                **plot_config[(group_var_name, metric_prefix, plot_key)]\n",
    "            )\n",
    "            ax_list[i, j].text(\n",
    "                0.02, 1, \n",
    "                string.ascii_uppercase[i*len(metrics) + j], \n",
    "                transform=ax_list[i, j].transAxes, \n",
    "                size=12, weight='bold')\n",
    "    fig.align_ylabels(ax_list[:, 0])\n",
    "\n",
    "    handles, labels = ax_list[-1, -1].get_legend_handles_labels()\n",
    "    fig.text(0.5, xlabel_height, r'Regularization $\\lambda$', ha='center', size=18)\n",
    "    plt.figlegend(\n",
    "        handles, labels, bbox_to_anchor=bbox_to_anchor, frameon=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_pivot['race_eth'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['lambda_group_regularization', 'race_eth', 'experiment', 'phase', 'group_objective_metric']\n",
    "(\n",
    "    data_dict_pivot['race_eth']\n",
    "    [id_cols + [x for x in data_dict_pivot['race_eth'].columns if 'delta_net_benefit_rr_recalib_0.075' in x]]\n",
    "    .query('group_objective_metric == \"mmd\"')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute='race_eth'\n",
    "group_objective_metric = \"mmd\"\n",
    "plot_key = 'performance'\n",
    "make_plot_grid(\n",
    "    data_dict_pivot[attribute].query('group_objective_metric == @group_objective_metric'), \n",
    "    attribute, \n",
    "    metrics=plot_keys_metrics_dict[plot_key],\n",
    "    plot_key=plot_key,\n",
    "    wspace = 0.2 if plot_key == 'net_benefit' else 0.3,\n",
    "    sharey = 'row' if plot_key == 'net_benefit' else 'none',\n",
    "    **plot_grid_config[attribute]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_path = '../zipcode_cvd/experiments/figures/optum/eo_rr/bootstrapped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute, group_objective_metric, plot_key in itertools.product(\n",
    "    attributes, \n",
    "    ['mmd', 'threshold_rate'], \n",
    "    plot_keys_metrics_dict.keys()\n",
    "):\n",
    "    \n",
    "    fig = make_plot_grid(\n",
    "        data_dict_pivot[attribute].query('group_objective_metric == @group_objective_metric'), \n",
    "        metrics=plot_keys_metrics_dict[plot_key], \n",
    "        group_var_name=attribute,\n",
    "        plot_key=plot_key,\n",
    "        wspace = 0.2 if plot_key == 'net_benefit' else 0.35,\n",
    "        sharey = 'row' if plot_key == 'net_benefit' else 'none',\n",
    "        **plot_grid_config[attribute]\n",
    "    )\n",
    "    figure_path = os.path.join(figures_path, attribute, group_objective_metric)\n",
    "    os.makedirs(figure_path, exist_ok=True)\n",
    "    plt.savefig(os.path.join(figure_path, 'metric_grid_{}.png'.format(plot_key)), dpi=180, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(figure_path, 'metric_grid_{}.pdf'.format(plot_key)), bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-hawaiian",
   "metadata": {},
   "source": [
    "## Plots of TPR/FPR variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_df(attribute, group_objective_metric):\n",
    "    plot_df = (\n",
    "        data_dict_pivot[attribute]\n",
    "        .query(f'{attribute} == \"Overall\"')\n",
    "        .query('group_objective_metric == @group_objective_metric')\n",
    "    )\n",
    "\n",
    "    keep_cols = ['lambda_group_regularization', 'experiment', 'group_objective_metric', attribute]\n",
    "    metric_cols = [x for x in plot_df.columns if 'var' in x and (('recall' in x) or ('fpr' in x))]\n",
    "    plot_df_long=plot_df.melt(id_vars=keep_cols, value_vars=metric_cols, var_name='metric', value_name='performance')\n",
    "    plot_df_long = (\n",
    "        plot_df_long.assign(\n",
    "            comparator = lambda x: x.metric.str.contains('comparator'),\n",
    "            tpr = lambda x: x.metric.str.contains('recall'),\n",
    "            t_075 = lambda x: x.metric.str.contains('0.075'),\n",
    "            recalib = lambda x: x.metric.str.contains('recalib')\n",
    "        )\n",
    "        .assign(\n",
    "            comparator_str = 'Absolute',\n",
    "            tpr_str = 'TPR',\n",
    "            t_075_str = '(7.5%)',\n",
    "            recalib_str = 'Calibrated'\n",
    "        )\n",
    "        .assign(\n",
    "            comparator_str = lambda x: x.comparator_str.where(x.comparator, 'Relative'),\n",
    "            tpr_str = lambda x: x.tpr_str.where(x.tpr, 'FPR'),\n",
    "            t_075_str = lambda x: x.t_075_str.where(x.t_075, '(20%)'),\n",
    "            recalib_str = lambda x: x.recalib_str.where(x.recalib, 'Unadjusted'),\n",
    "            tpr_t_str = lambda x: x.tpr_str.str.cat(x.t_075_str, sep=' '),\n",
    "            ci_var_str = lambda x: x.metric.str.split('var_').str[-1]\n",
    "        )\n",
    "    )\n",
    "    plot_df_long_pivot = plot_df_long.pivot(\n",
    "        index=set(plot_df_long.columns) - set(['ci_var_str', 'performance', 'metric']),\n",
    "        columns = 'ci_var_str',\n",
    "        values='performance'\n",
    "    ).reset_index()\n",
    "    return plot_df_long_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_dict = {\n",
    "    (attribute, group_objective_metric): prepare_plot_df(attribute, group_objective_metric)\n",
    "    for attribute, group_objective_metric in itertools.product(\n",
    "        ['race_eth', 'gender_concept_name', 'race_eth_gender'],\n",
    "        ['mmd', 'threshold_rate']\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_dict[('race_eth', 'mmd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_config = {\n",
    "    ('race_eth', 'Absolute'): {\n",
    "        'ylim': (-0.0025, 0.03),\n",
    "        'ylabel': 'IG-Var'\n",
    "    },\n",
    "    ('race_eth', 'Relative'): {\n",
    "        'ylim': (-0.015, 0.015),\n",
    "        'ylabel': 'IG-Var (rel)'\n",
    "    },\n",
    "    ('gender_concept_name', 'Absolute'): {\n",
    "        'ylim': (-0.0025, 0.015),\n",
    "        'ylabel': 'IG-Var'\n",
    "    },\n",
    "    ('gender_concept_name', 'Relative'): {\n",
    "        'ylim': (-0.01, 0.012),\n",
    "        'ylabel': 'IG-Var (rel)'\n",
    "    },\n",
    "    ('race_eth_gender', 'Absolute'): {\n",
    "        'ylim': (-0.0025, 0.04),\n",
    "        'ylabel': 'IG-Var'\n",
    "    },\n",
    "    ('race_eth_gender', 'Relative'): {\n",
    "        'ylim': (-0.015, 0.04),\n",
    "        'ylabel': 'IG-Var (rel)'\n",
    "    },\n",
    "}\n",
    "\n",
    "plot_keys = ['TPR (7.5%)', 'FPR (7.5%)', 'TPR (20%)', 'FPR (20%)']\n",
    "comparator_keys = ['Absolute', 'Relative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_grid(\n",
    "    df, \n",
    "    attribute, \n",
    "    wspace=0.2, \n",
    "    hspace=0.25,\n",
    "    bbox_to_anchor=(1.07, 0.6),\n",
    "    xlabel_height=-0.05,\n",
    "    sharey=None\n",
    "):\n",
    "    plt.close()\n",
    "    fig, ax_list = plt.subplots(\n",
    "        len(comparator_keys), len(plot_keys), squeeze=False, figsize=(10,1.5*len(comparator_keys)), dpi=180\n",
    "    )\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "    for j, plot_key in enumerate(plot_keys):\n",
    "        for i, comparator_key in enumerate(comparator_keys):\n",
    "\n",
    "            temp = (\n",
    "                df\n",
    "                .query('tpr_t_str == @plot_key')\n",
    "                .query('comparator_str == @comparator_key')\n",
    "            )\n",
    "\n",
    "            temp = temp.sort_values('recalib_str', ascending=False)\n",
    "\n",
    "            plot_data(\n",
    "                temp,\n",
    "                ax=ax_list[i, j],\n",
    "                x_var='lambda_group_regularization', \n",
    "                y_var='mid',\n",
    "                group_var_name='recalib_str',\n",
    "                use_symlog_x=True,\n",
    "                symlog_x_linthresh=1e-2,\n",
    "                ci_lower_var='lower',\n",
    "                ci_upper_var='upper',\n",
    "                ci_type='errorbar',\n",
    "                errorbar_capsize=5,\n",
    "                plot_x_axis=comparator_key == 'Relative',\n",
    "                ylim=plot_config[(attribute, comparator_key)].get('ylim'),\n",
    "                legend=False,\n",
    "                hide_yticks= j > 0,\n",
    "                hide_xticks= i + 1 < len(comparator_keys),\n",
    "                ylabel=plot_config[(attribute, comparator_key)].get('ylabel') if j == 0 else None,\n",
    "                title = plot_key if i == 0 else None,\n",
    "                groupby_sort=False,\n",
    "                ylabel_fontsize=12\n",
    "            )\n",
    "            ax_list[i, j].text(\n",
    "                0.02, 1, \n",
    "                string.ascii_uppercase[i*len(plot_keys) + j], \n",
    "                transform=ax_list[i, j].transAxes, \n",
    "                size=12, weight='bold')\n",
    "    handles, labels = ax_list[-1, -1].get_legend_handles_labels()\n",
    "    fig.text(0.5, xlabel_height, r'Regularization $\\lambda$', ha='center', size=18)\n",
    "    fig.align_ylabels(ax_list[:, 0])\n",
    "    plt.figlegend(\n",
    "        handles, labels, bbox_to_anchor=bbox_to_anchor, frameon=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute = 'race_eth'\n",
    "# attribute = 'gender_concept_name'\n",
    "attribute = 'race_eth_gender'\n",
    "group_objective_metric = 'mmd'\n",
    "# group_objective_metric = 'threshold_rate'\n",
    "plot_df = plot_df_dict[(attribute, group_objective_metric)]\n",
    "\n",
    "make_plot_grid(\n",
    "    df = plot_df,\n",
    "    attribute=attribute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute, group_objective_metric in itertools.product(\n",
    "    attributes, \n",
    "    ['mmd', 'threshold_rate'], \n",
    "):\n",
    "    \n",
    "    fig = make_plot_grid(\n",
    "        plot_df_dict[(attribute, group_objective_metric)], \n",
    "        attribute=attribute\n",
    "    )\n",
    "    figure_path = os.path.join(figures_path, attribute, group_objective_metric)\n",
    "    os.makedirs(figure_path, exist_ok=True)\n",
    "    plt.savefig(os.path.join(figure_path, 'tpr_fpr_var.png'), dpi=180, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(figure_path, 'tpr_fpr_var.pdf'), bbox_inches='tight')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
